# Java基础
## OOP


## equals() 和 hashCode() 
* `==` 用于基本类型变量值的相等判断；
* `equals()` 用于对象相等的判断：
	* Object类的equals方法内部是判断两个对象引用是否相等（地址是否相等）；
	* 一般需要判断的是两个引用类型变量的内部属性是否相等，所以需要重写equals；
* 重写equals：
	* 判断引用是否相等；
	* 判断对象类型是否相等；
	* 判断对象内部属性是否相等；
* `hashCode()`用于获取对象的哈希码：
	* Object类的hashCode方法是native的，底层由C/Cpp实现；**原生的hashCode()方法为不同的对象返回不同的整型值** ，这个整形值可能与对象的内存地址有关，但具体实现要看JVM版本；
	* 对象用于`散列表` 时，需要重写hashCode方法；
* 重写hashCode：
	* 可以使用`Objects.hash()` 方法等等；
	* 对对象的属性值按某个哈希函数进行哈希运算；
* 为什么重写equals，一定要重写hashCode？
	* 原因：出于效率
	* 在HashSet、HashMap、HashTable等集合中元素是无序的且不重复的，若单靠equals方法比较，时间复杂度是O(n)，但有了hashCode方法后，我们可以获取该对象的hash值用O(1)的时间复杂度来定位；若该位置上已有对象，使用equals方法进行判断对象内部属性是否相等。
	* 重写equals是为了判断两个对象内部属性是否相等，重写hashCode是为了保证equals相等的两个对象，一定能在散列表中落到同一个`桶` 中。
* 总结：
	* 两个对象的hashCode相等，那么这两个对象不一定相等（哈希碰撞）；
	* 两个对象的hashCode相等，且两个对象的equals返回true，那么认为这两个对象相等；
	* 两个对象的hashCode不相等，那么可以直接认为这两个对象不相等；


## System.identityHashCode()
> identityHashCode和hashCode的区别是，identityHashCode会返回对象的hashCode，而不管对象是否重写了hashCode方法。

* 对象重写了hashCode：
	* `obj.hashCode()`返回重写后计算的值；
	* `System.identityHashCode(obj)`返回原hashCode值（每个对象唯一的）；
* 对象没有重写hashCode：
	* `hashCode`与`identityHashCode`返回值相同；
```java

```
## String、StringBuilder、StringBuffer
- String为什么不可变：
	- 什么是不可变：当给String赋一个字符串字面值时，改变的是String引用所指向的地址，而不是String原指向字符串的值--这里有一个字符串常量池的概念；
	- String类型是`final`修饰的：保证了String类型不可被继承；
	- String底层使用了一个`private final`修饰的`char[]`：
		- final修饰保证了这个char[] 不会指向别的对象；
		- private保证了这个对象的不可见性（且String是不可继承的）；
		- 且没有提供修改这个char[]中元素的方法；
	- 这种不可变的好处：安全，比如在使用String作为参数传递时，不会发生对原String不易发现的修改；

- StringBuffer、StringBuilder：
	- 都继承自`AbstractStringBuilder`，底层使用没有任何修饰的`char[]`来保存字符串，且提供了很多修改字符串的方法；
	- StringBuffer中很多对字符串的操作都加了`synchronized`关键字，所以是线程安全的；StringBuilder线程不安全；

- 字符串拼接用`+`还是`StringBuilder`？
	- `+`、`+=`是Java中仅有的两个重载过的运算符，且专门为String类重载；
	- JDK1.8及之前，在循环内使用`+`、`+=`实现字符串拼接，每循环执行一次，底层编译器就会创建一个`StringBuilder`对象进行拼接；
	- JDK1.9开始，字符串相加 “+” 改为了用动态方法 makeConcatWithConstants() 来实现，而不是大量的 StringBuilder 了。

- String重写过的equals：比较的是字符串的值是否相等。
- 字符串常量池的作用：JVM 为了提升性能和减少内存消耗针对字符串（String 类）专门开辟的一块区域，主要目的是为了避免字符串的重复创建。
- String#intern方法的作用：
	- `s1.intern()`：若s1直接指向字符串常量池中的字符串引用，则返回该引用；
	- `s1.intern()`：若s1指向堆空间的字符串对象，直接返回该对象在常量池中的字符串引用；

- String类型的变量和常量做`+`运算时发生了什么？

## 常量折叠
常量折叠会把常量表达式的值求出来作为常量嵌在最终生成的代码中，这是 Javac 编译器会对源代码做的极少量优化措施之一(代码优化几乎都在即时编译器中进行)。

对于`String str3 = "str" + "ing"`，编译器会优化成`String str3 = "string"`；

**只有编译器在程序编译期间就可以确定的常量值才会进行常量折叠**：

- 基本数据类型( byte、boolean、short、char、int、float、long、double)以及字符串常量。
- final 修饰的基本数据类型和字符串变量
- 字符串通过 “+”拼接得到的字符串、基本数据类型之间算数运算（加减乘除）、基本数据类型的位运算（<<、>>、>>> ）
## 包装类型
>Java 基本数据类型的包装类型的大部分都用到了缓存机制来提升性能。

`Byte、Short、Integer、Long`四种包装类型默认创建了`[-128, 127]` 的相应类型的缓存数据；
`Character` 创建了数值在`[0, 127]` 范围的缓存数据；
`Boolean` 直接返回`true` Or`false`；
* 自动拆箱与自动装箱
	* 装箱：将基本数据类型变量用它们对应的引用类型包装起来;
	* 拆箱：将包装类型变量转换为对应的基本数据类型变量；
```java
class Main {
	public static void main(String[] args) {
		Integer i = 10;//自动装箱：Integer i = new Integer(10);
		int j = i;//自动拆箱：
	}
}
```

## BigDecimal
## Throwable



# Java集合
![](Java容器继承图.png)
可省略为：
![](Java主要集合框架.png)

## Collection接口
> 三大子接口：Set、List、Queue


## Map接口

* `Collection<V> values();`：返回map的所有value的集合，可以作为ArrayList的构造参数。


## ArrayList
```java
public class ArrayList<E> extends AbstractList<E>  
        implements List<E>, RandomAccess, Cloneable, java.io.Serializable  
{
	//...
}
```
* 是否线程安全：否，方法都没有使用`synchronized`关键字；
* 底层数据结构：底层是Object数组，支持动态扩容；
* 插入和删除是操作：
	* 直接插入：默认插入到数组尾部，时间复杂度为O(1)；
	* 指定位置插入：需要移动大量元素，时间复杂度为O(n)；
	* 指定元素移除/指定位置移除：时间复杂度O(n)；
* 快速访问：实现了`RandomAccess`接口，支持快速访问，通过索引直接访问底层数组；
* 内存空间占用：数组尾部会预留一定空间；
### 扩容机制
* 未指定容量初始化的空list，底层数组容量为0；
* 当加入第1个元素后，底层数组容量变为10；
* 当加入第11个元素后，底层数组触发`grow`扩容，扩容到原来的`1.5`倍；
### System.arraycopy() 和 Arrays.copyOf()
* ArrayList中的add方法用到了System.arraycopy()：当在指定位置添加元素时，需要将原有的一部分数据向后拷贝一位；
* ArrayList中的toArray()方法用到了Arrays.copyOf()：从原来的底层数组中，复制出一个新的数组并返回；

## LinkedList
```java
public class LinkedList<E> extends AbstractSequentialList<E>
		implements List<E>, Deque<E>, Cloneable, java.io.Serializable
{
	//...
}
```
* 是否线程安全：否
* 插入和删除操作：底层使用双向链表结构（非循环）
	* 头部插入、删除：O(1)；
	* 尾部插入、删除：O(1)；
	* 指定位置插入、删除：O(n)；
* 快速访问：LinkedList底层是链表，地址不连续，不支持快速访问，因此不能实现`RandomAccess`接口；
* 内存空间占用：链表的每个节点都拥有两个指针
### 删除节点
> 删除节点的核心方法是`unlink(Node<E> x)`方法
* 首先获取待删除节点x的前驱pre和后继节点next；
* 判断待删除节点x是否为头结点或尾节点：
	* 若x是头节点，则将虚拟头结点的后继指针指向x的后继节点，将x的后继节点的前驱指针指向虚拟头节点；
	* 若x是尾节点，则将虚拟尾节点的前驱指针指向x的前驱节点，将x的前驱节点的后继指针指向虚拟尾节点；
	* 若x不是头节点，也不是尾节点，执行下一步操作；
		* 将待删除节点x的前驱节点的后继指针指向x的后继节点pre，将x的前驱指针置为null；
		* 将待删除节点x的后继节点的前驱指针指向x的前驱节点next，将x的后继指针置为null；
* 将待删除节点x置为nul，修改链表长度；

## HashMap
> 主要用于存放键值对，实现了Map接口，非线程安全。
```java
public class HashMap<K,V> extends AbstractMap<K,V>
		implements Map<K,V>, Cloneable, Serializable 
{
	//...
}
```

* 设计组成：JDK1.8之前，HashMap底层是 `数组 + 链表`实现；JDK1.8之后，HashMap底层是`数组 + 链表/红黑树`实现（在链表长度达到某个阈值时，转化为红黑树；在红黑树节点数小于某个阈值时，退化为链表）
* 重要属性：
	* `loadFactor--负载因子`：
		* 
	* `threshold--阈值`：
		* `threshold = capacity * loadFactor`，当`size > threshol`时，就需要考虑对数组进行扩容，会设计到rehash。
	* `Node节点`：
	* `TreeNode节点`：

![](HashMap底层结构.png)
* **桶数组是用来存储数据元素的，链表是用来解决哈希冲突的，红黑树是为了提高查询的效率**；
* 数据元素通过映射关系（扰动函数获取hash值，再对(length-1)做`&`运算），映射到桶数组对应索引的位置；
* 若发生冲突（不相等的两个元素被映射到同一个位置/元素被映射到的位置已经存在元素了），从冲突的位置拉一个链表，插入冲突的元素；
* 若`链表长度 > 8 & 数组capacity >= 64`，链表转化为红黑树；若链表长度大于8，但数组容量小于64，则只进行数组扩容（2倍扩容）；
* 若红黑树节点个数小于6，红黑树转化为链表；
### 红黑树的概念
> 本质上是一种保持平衡的二叉查找树（搜索树）。
![](红黑树.png)
* 红黑树的基本规则：
	* 只有红黑两种节点；
	* 根节点永远是黑色；
	* 所有叶子节点（NULL值节点）都是黑色的；
	* 每个红节点的两个子节点一定是黑色；
	* 从任一节点到其子树中每个叶子节点的路径都包含相同数量的黑色节点；
* 与二叉树、平衡二叉树的对比：
	* 红黑树的插入、删除、查找操作的最坏时间复杂度都是`O(logn)`。
	* 对比二叉树：最坏情况下插入、删除、查找操作的时间复杂度是`O(n)`（退化成了链表）。
	* 对比平衡二叉树：平衡二叉树为了保持平衡（每个节点的左右子树高的差值的绝对值<=1），需要旋转的次数更多，插入和删除效率低。
* 红黑树保持平衡：
	* 两种方式：`旋转`、`染色`
	* 旋转：
		* 左旋：
		* 右旋：
	* 染色：
### 链表与红黑树的转换




# Java IO

# Java反射、动态代理


# JVM


# JUC
## 线程死锁
[[OS与Linux#死锁]]

## synchronized锁升级原理
> synchronized锁升级原理涉及Java对象内存布局、JVM指针压缩。

### JVM指针压缩
> 32位系统内存不够用，64位系统内存够用但太大影响性能（GC、CPU）
> 使用`压缩指针`，在64位的操作系统中利用32位的对象指针引用获得超过4G的内存寻址空间。
1. 第一步压缩：32/64位系统中，对象地址的末尾三位固定都是0，这3位0可以不存储，而用多出来的3位存储额外的地址信息。即寻址的时候，左移三位，补3个0，寻址范围大约变成了32G；压缩的时候右移3位，隐藏这三个0。
2. 可以通过设置虚拟机参数来改变对象对齐的字节倍数，若设置为16的倍数，那么就会多出4bit，寻址范围扩大到了64G。
> 最好还是保持32G，即按8字节对齐。

### Java对象结构
> Java对象由三部分组成。
1. 对象头：对象头也由三部分组成。
	1. Mark Word：存储对象的hashCode、垃圾回收对象的年龄、锁信息等；
	2. 类型指针：指向该对象的Class类型的内对地址。
	3. 数组长度：若对象是数组，才有这部分数据；否则没有，不分配空间。
2. 对象体：对象所有非静态属性占用的空间（包括父类的所有属性，不包括方法），若属性是基本数据类型则直接存本身，若属性是引用类型则存指针（引用）。
3. 对齐填充：对象头 + 对象体所占空间不是8字节的倍数，则填充使整个对象结构为8字节的倍数。
#### 对象头
> 12字节或16字节，以下默认为开启了指针压缩。若没有开启指针压缩，那么类型指针变为8字节。
##### Markword（8字节）
> 占64bit，存储对象的hashCode、GC年龄、锁状态
![](对象结构-对象头-Markword.png)

##### 类型指针（4字节）
> 为什么类型指针是4字节？压缩指针的情况下只有32位，其他3位0隐藏。
##### 数组长度（0或4字节）

#### 对象体
存放的是非静态属性对象（包括父类的所有非静态属性，不区分可见性修饰符），基本类型的属性存放的是具体的值，引用类型（包括数组类型）存放的是引用指针。

#### 对齐填充


### synchronized锁升级
> synchronized可保证原子性、可见性、有序性（执行结果的有序性而不是指令重排的有序性）

#### 作用在xxx上，锁的是xxx
1. 静态方法，类class
2. 普通方法，对象实例
3. 代码块，括号内 类class/对象实例
#### 原理分析
> 会使用到对象结构中对象头中的8字节的Markword信息。
![](对象结构-对象头-Markword.png)
#### 锁状态
> 无锁、偏向锁、轻量级锁、重量级锁。

* 无锁：该状态下，没有线程获取锁。
* 偏向锁：共享资源首次被访问时，JVM会对共享资源对象做一些设置：
	* 对象头中是否偏向锁标志置为1；
	* 对象头中偏向线程ID设置为当前线程ID；
	后续当前线程再访问该共享资源时，会根据偏向锁标识和偏向线程ID进行对比是否相同，比对成功则直接获取到锁，进入临界区域，这也就是synchronized的`可重入功能`。
* 轻量级锁：当多个线程同时申请共享资源的访问时，就产生了竞争，JVM会先尝试使用轻量级锁，让线程以CAS方式获取锁，（自旋加锁，不阻塞线程，采用循环等待的方式），若成功获取到锁，则锁状态为轻量级锁，若自旋达到一定次数还未成功（失败了）则锁升级到重量级锁。
* 重量级锁：若共享资源锁已经被某个线程所持有，此时时偏向锁状态，未释放锁前，再有其他线程来竞争时，会升级到重量级锁；另外当轻量级锁状态下，多线程竞争锁时，也会升级到重量级锁。重量级锁由操作系统实现，性能消耗相对较高。

#### 锁升级
> 锁升级是针对于synchronized锁在不同竞争条件下的一种优化，根据锁在多线程中竞争的程度和状态，synchronized锁可在无锁、偏向锁、轻量级锁和重量级锁之间进行流转，以降低获取锁的成本，提高获取锁的性能。

#### synchronized优化
* JDK1.6之前，synchronized是直接通过`ObjectMonitor`中的`monitorenter、monitorexit、ACC_SYNCHRONIZED`实现的，属于重量级锁，依靠操作系统的`mutex`实现。
* JDK1.6开始，synchronized引入了锁升级的策略，如适应性自旋、锁消除、锁粗化、轻量级锁和偏向锁等优化策略，提供了性能。
	* 偏向锁
	* 轻量级锁：多个线程在不同时间段获取同一把锁，不存在锁竞争的情况，也就没有线程阻塞，JVM使用轻量级锁避免线程的阻塞和唤醒。当一个线程尝试获取轻量级锁时，会在自己的栈帧中创建一个锁记录`Lock Record`，尝试使用CAS操作将对象头的Markword替换为指向锁记录的指针。
	* 自旋锁：获取轻量级锁失败，进入自旋，自旋失败，转为重量级锁。
	* 锁粗化：如果 JVM 检测到一系列连续的锁操作实际上是在单一线程中完成的，则会将多个锁操作合并为一个更大范围的锁操作，这可以减少锁请求的次数。锁粗化主要针对循环内连续加锁解锁的情况进行优化。
	* 锁消除：JVM 的即时编译器JIT可以在运行时进行代码分析，如果发现某些锁操作不可能被多个线程同时访问，那么这些锁操作就会被完全消除。锁消除可以减少不必要的同步开销。








## Lock接口
### xxx

### ReentrantLock
> 可重入锁。
* Sync内部类（继承自`AQS`）
* NonfairSync内部类（继承自Sync）---非公平锁。
	* 默认创建的是非公平锁。
	* 锁可能会分配给刚刚请求它的线程，而不考虑等待时间。
* FairSync内部类（继承自Sync）---公平锁。
	* 构造方法传入true，创建公平锁。
	* 锁会按先来先得的队列形式，等待时间最长的线程获取锁。

* lock()：
	* 检查当前锁是否被其他线程所持有，若持有，则加入等待队列中；
	* 首次获取锁时，计数器+1，每重入一次，计数器+1；
* unLock()：
	* 每释放一次锁，计数器-1；
	* 计数器减到0，则释放锁；
> 计数器指的是AQS中的state，会采用CAS的方式设置state。

### ReentrantReadWriteLock

## AQS
> `AbstractQueuedSynchronizer`，抽象同步队列。
> AQS 就是一个抽象类，主要用来构建锁和同步器。
> AQS 为构建锁和同步器提供了一些通用功能的实现，因此，使用 AQS 能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的 `ReentrantLock`，`Semaphore`，其他的诸如 `ReentrantReadWriteLock`，`SynchronousQueue`等等皆是基于 AQS 的。


* 核心思想：
	* 如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态；
	* 如果被请求的共享资源被占用，则需要一套线程阻塞等待以及被唤醒时锁分配的机制，AQS使用`CLH`队列锁来实现，即将暂时获取不到锁的线程加入到该队列中。
* CLH队列：是一个虚拟的双向队列（不存在队列实例，进存在节点之间的关联关系）。AQS将每条请求共享资源且暂时获取不到锁的线程封装成一个Node加入到CLH队列当中来实现锁的分配。一个Node表示一个线程，保存线程的引用、当前节点在队列中的状态、前驱节点、后继节点。
* state：AQS使用volatile修饰的int成员变量state来表示同步状态，通过`CLH`队列来完成请求获取资源线程的排队工作。

## CAS
> CompareAndSwap，比较并交换。
> 主要通过处理器的指令来保证操作的原子性。

* CSA指令包含3个参数，共享变量的内存地址A，预期值B，共享变量的新值C；
* 仅当内存地址A处的值等于B时，才能将内存地址A处的值更新为C，作为一条CPU指令，CAS指令本身是能够保证原子性的。

* CAS三大经典问题：
	* ABA问题：
		* 修改共享变量时，其值为A，就会执行修改，但是修改期间，该值又被其他线程修改成了B，然后又被其他线程修改成了A，这样就导致了该值虽然修改成功，但是修改也发生了数据变化。
		* 解决--加版本号，每次修改都对版本号+1，那么ABA问题就会导致他的版本号发生变化，我们修改时就会发现版本号不一致导致修改失败。
	* 循环性能开销：
		* CAS会一直循环执行，若一直不成功，CPU开销大；
		* 解决--设置自旋次数，超过一定次数，停止自旋。
	* 只能保证一个变量的原子操作：
		* 解决--对多个变量的操作加锁保证原子性。
		* 解决--封装多个变量为一个对象进行CAS操作，通过AtomicRefrence保证原子性。
## Java保证原子性的方法
* 使用循环原子类：AtomicXxx，如AtomicInteger，AtomicRefrecne等；
* 使用juc下的锁，ReentrantLock；
* 使用synchronized；

## AtomicInteger的原理
> 使用CAS实现


## 线程池
> 池化技术的思想主要是为了减少每次获取资源的消耗，提高对资源的利用率。
> 线程池创建的两种方式：`ThreadPoolExecutor`构造函数、`Executor框架的工具类Executors`创建

### 常用阻塞队列
> 新任务到来时，当前正在运行的线程数量是否达到了核心线程数量，如果达到了就将新任务加入阻塞任务队列中等待执行。
* `ArrayBlockingQueue`：数组实现的有界队列，传参定义大小，按FIFO排序。
* `LinkedBlockingQueue`：容量为`Integer.MAX_VALUE`的无界队列。
* `DelayQueue`：按照指定的延时时间任务进行排序，内部是基于堆实现的。
* `PriorityBlockingQueue`：具有优先级的无界阻塞队列。
* `SynchronousQueue`：不存储元素，目的是保证对于提交的任务，如果有空闲线程则使用空闲线程来处理，否则创建一个线程来处理任务。

### 线程池饱和策略/拒绝策略
> 当线程池中同时运行的线程数达到了最大线程数量，且任务队列已经放满任务时，ThreadPoolExecutor定义了一些饱和策略来拒绝新来的任务。

* `ThreadPoolExecutor.AbortPolicy`：抛出异常拒绝新任务的处理（RejectExecutionException）；
* `ThreadPoolExecutor.CallerRunPolicy`：让提交任务的线程也就是执行`execute`方法的线程自己来执行该任务；
* `ThreadPoolExecutor.DiscardPolicy`：不处理直接丢弃，也不抛异常。
* `ThreadPoolExecutor.DiscardOldestPolicy`：丢弃最早的未处理的任务，尝试将新任务加入任务队列。

### ThreadPoolExecutor构造函数创建线程池
* 参数：
	* `corePoolSize`-线程池的核心线程数量：任务队列未达到队列容量时，最大可以同时运行的线程数量。
	* `maximumPoolSize`-线程池的最大线程数量：任务队列达到队列容量时，当前可以同时运行的线程的数量变为最大线程数。
	* `workQueue`-任务队列：新任务到来时会判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务会被放到任务队列中等待线程执行。

	* `keepAliveTime`：核心线程之外的其他线程，空闲时最大等待时间，超过这个时间如果还没有任务执行就会被销毁。
	* `unit`：keepAliveTime参数的时间单位
	* `threadFacotry`-线程工厂：executor创建新线程时会用到
	* `handler`-饱和策略：

### 线程池原理
* 提交任务；
* 判断当前运行线程数是否达到最大核心线程数；
	* 否，创建新线程处理任务立刻执行这个任务；
* 是，判断任务队列是否已满；
	* 否，加入任务队列；
* 是，判断线程数是否达到最大线程数；
	* 否，创建新线程立刻执行这个任务；
* 是，根据拒绝策略处理；

### Executor框架内置线程池
> 框架内内置了线程池：

* `FixedThreadPool`--可重用固定线程数的线程池
	* corePoolSize和maximumPoolSize相等；
	* 使用的是容量为`Integer.MAX_VALUE`的`LinkedBlockingQueue`，队列不会放满；
	* 缺点：
		* 不会拒绝任务，任务太多时会OOM（内存溢出）
* `SingleThreadExecutor`--只有一个线程的线程池
	* corePoolSize和maximumPoolSize都为1；
	* 使用无界队列；
	* 缺点：
		* 任务太多，OOM
* `CachedThreadPoll`--根据需要创建新线程的线程池
	* corePoolSize为0，maximumPoolSize为Integer.MAX_VALUE；
	* 使用不存储任务的`SynchronousQueue`；
	* 提交任务，若有空闲线程就交给空闲线程处理，否则就创建新线程执行，创建过多会耗尽cpu和内存资源；
* `ScheduledThreadPoll`--定期执行任务的线程池
	* 使用`DelayQueue`任务队列，按照延迟时间从小到大排序，1.5倍数扩容，不会阻塞，最大为Integer.MAX_VALUE；

